{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3\n",
    "- No Manual prescoring\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "root_pth = str(Path.cwd().parent)\n",
    "if root_pth not in sys.path:\n",
    "    sys.path.insert(0, root_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Preprocessing\n",
    "- Load data\n",
    "- Strip whitespace \n",
    "- Convert \"Creation date\" column to string\n",
    "- Add year to \"Name\" column where missing, use year from creation date: \"PDP |\" -> \"PDP 2020 |\"\n",
    "- Add delimiter to \"Name\" column where missing: \"PDP 2020 |\" -> \"PDP | 2020 |\"   \n",
    "- Lower text in Name column\n",
    "- Seperate Url from Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "from IPython.display import display_html\n",
    "import pandas as pd\n",
    "\n",
    "class TextPreprocessing():\n",
    "\n",
    "    def __init__(self,pth):\n",
    "            self.punctuation = list(string.punctuation)\n",
    "            self.has_year_in_it = r\".*([1-3][0-9]{3})\"\n",
    "            self.has_pipe_in_it = r\"\\bPDP\\b\\s\\|\"\n",
    "            self.mlen = 50\n",
    "            self.pth = pth \n",
    "\n",
    "    def get_data(self):\n",
    "        self.data = pd.read_excel(self.pth)\n",
    "        return(self)\n",
    "\n",
    "\n",
    "\n",
    "    def add_missing_year(self,verbose=True):\n",
    "            name = self.data[\"Name\"]\n",
    "            goal_or_result = self.data[\"Goal / Key Result\"]\n",
    "            date = self.data[\"Deadline\"]\n",
    "            print(\"--- Add missing year \".ljust(79,'-')) \n",
    "            for count, val in enumerate(name):\n",
    "                if goal_or_result[count] == \"Goal\":\n",
    "                    year = datetime.strptime(date[count], \"%d-%m-%Y\").year\n",
    "                    if not re.match(self.has_year_in_it, val):\n",
    "                        string_with_year = f\"PDP {str(year)} \" + val.split(\"PDP \", 1)[1]\n",
    "                        \n",
    "                        if verbose:\n",
    "                            short_form_pre = val[:self.mlen].ljust(self.mlen )\n",
    "                            short_form_post = string_with_year[:self.mlen].ljust(self.mlen)\n",
    "                            print(short_form_pre, \"->\", short_form_post)\n",
    "                        \n",
    "                        name.iat[count] = string_with_year\n",
    "                        \n",
    "            self.data[\"Name\"] = name\n",
    "              \n",
    "            return self\n",
    "\n",
    "\n",
    "\n",
    "    def add_missing_delimiter(self, verbose=True):\n",
    "        \n",
    "        name = self.data[\"Name\"]\n",
    "        print(\"--- Add missing delimiter \".ljust(79,'-'))\n",
    "        for count, val in enumerate(name):\n",
    "            print(val)\n",
    "            missing_year = re.match(self.has_year_in_it, val)\n",
    "            with_pipe = re.match(self.has_pipe_in_it, val) \n",
    "            if missing_year and not with_pipe:\n",
    "                string_with_pipe = \"PDP | \" + val.split(\"PDP \", 1)[1]\n",
    "\n",
    "                if verbose:\n",
    "                        short_form_pre = val[:self.mlen].ljust(self.mlen )\n",
    "                        short_form_post = string_with_pipe[:self.mlen].ljust(self.mlen)\n",
    "                        print(short_form_pre, \"->\", short_form_post)\n",
    "\n",
    "                name.iat[count] = string_with_pipe\n",
    "\n",
    "        self.data[\"Name\"] = name\n",
    "         \n",
    "        return self\n",
    "\n",
    "    def extract_url(self):\n",
    "        url = []\n",
    "        description = []\n",
    "\n",
    "        for d in self.data[\"Description\"]:\n",
    "            match = re.search(r'http\\S+',str(d))\n",
    "            if not isinstance(d,float) and match:\n",
    "                url.append(match[0])\n",
    "                description.append(re.sub(r'http\\S+', '', d))\n",
    "            else:\n",
    "                url.append(\"\")\n",
    "                description.append(\"\")\n",
    "        self.data[\"Url\"] = url\n",
    "        self.data[\"Description\"] = description\n",
    "\n",
    "        print(\"--- Extract url \".ljust(79,'-'))\n",
    "        display_html(self.data[[\"Url\",\"Description\"]].head(5))\n",
    "        return(self)\n",
    "\n",
    "    def lower_col(self,colnames):\n",
    "        for col in  colnames:\n",
    "            self.data[col] = self.data[col].str.lower()\n",
    "        return(self)\n",
    "\n",
    "    def rm_punctuations(self,colnames):\n",
    "        \"\"\"Removes hyphens from field \n",
    "        \"\"\"\n",
    "        import re\n",
    "        for col in  colnames:\n",
    "            self.data[col] = self.data[col].apply(lambda x: \n",
    "                                    re.sub(\"-\",\"\",x) if isinstance(x,str)\n",
    "                                    else x \n",
    "                                        )\n",
    "        return(self)\n",
    "\n",
    "    def strip_cols(self,colnames):\n",
    "        for col in  colnames:\n",
    "            self.data[col] = self.data[col].str.strip()\n",
    "        return(self)\n",
    "\n",
    "    def change_col_type(self):\n",
    "        self.data = self.data.astype({\"Deadline\": str}, errors=\"raise\")\n",
    "        return(self)\n",
    "\n",
    "    def filter_by_value(self):\n",
    "        \"\"\"Split data into Goals and Results dfs.\n",
    "        \"\"\"\n",
    "        print('Split Data into Goals and Results')\n",
    "        self.Goals = self.data[self.data[\"Goal / Key Result\"] == \"Goal\"].reset_index(drop=True)\n",
    "        self.Results = self.data[self.data[\"Goal / Key Result\"] == \"Key Result\"].reset_index(drop=True)\n",
    "        return(self)\n",
    "\n",
    "    def split_by_pipe(self):\n",
    "        \"\"\"Split Name by delimiter \n",
    "\n",
    "        Example: \n",
    "        Name\n",
    "        PDP 2022 | Q2 | AWS Machine Learning Plan durc...\n",
    "\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        new_columns = [\"Type\", \"Goal Year\", \"Goal Quarter\", \"Tmp\"]\n",
    "        self.Goals[new_columns] = self.Goals[\"Name\"].str.split(\"|\", expand=True)\n",
    "        self.Goals[new_columns] = self.Goals[new_columns].apply(lambda x: x.str.strip())\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def drop(self):\n",
    "        return self.data.drop\n",
    "    \n",
    "    @property\n",
    "    def rename(self):\n",
    "        return self.data.rename\n",
    "    \n",
    "    @property\n",
    "    def apply(self):\n",
    "        return self.data.apply\n",
    "\n",
    "    @property\n",
    "    def loc(self):\n",
    "        return self.data.loc\n",
    "\n",
    "    def split_name_by_pipe(self):\n",
    "        import numpy as np\n",
    "        new_columns = [\"Type\", \"Goal Year\", \"Goal Quarter\", \"Tmp\"]\n",
    "        self.data[new_columns] = self.data[\"Name\"].str.split(\"|\", expand=True)\n",
    "        self.data[new_columns] = self.data[new_columns].apply(lambda x: x.str.strip())\n",
    "        self.data = self.data.drop(columns=\"Name\")\n",
    "        #\n",
    "        idx_result = np.where(self.data[\"Goal / Key Result\"] == \"Key Result\")\n",
    "        self.data.loc[idx_result[0],\"Tmp\"] = self.data.iloc[idx_result[0]][\"Type\"]\n",
    "        #\n",
    "        idx_type = np.where(self.data[\"Type\"] != \"pdp\")\n",
    "        self.data.loc[idx_type[0],\"Type\"] = None\n",
    "\n",
    "        self.data.rename(columns={\"Tmp\": \"Name\"}, inplace=True)\n",
    "        return (self)\n",
    "\n",
    "    def preprocess_goals(self):\n",
    "            print(\"Split Name into Type, Goal Year, Goal Quarter and Topic\")\n",
    "            self.split_by_pipe()\n",
    "            print(\"Drop Name and Parent ID\")\n",
    "            self.Goals.drop(columns=[\"Name\", \"Parent ID\"], inplace=True)\n",
    "            print(\"Rename Tmp back into Name\")\n",
    "            self.Goals.rename(columns={\"Tmp\": \"Name\"}, inplace=True)\n",
    "            return(self)\n",
    "    \n",
    "    def combine_text(self):\n",
    "\n",
    "        self.data[\"text\"] = self.data[\"Name\"] + \". \" + self.data[\"Description\"] \n",
    "        return(self)\n",
    "\n",
    "    def fill_na(self, columns_to_fill):\n",
    "        for col in columns_to_fill:\n",
    "            self.data[col].fillna(0,inplace=True)\n",
    "        return(self)\n",
    "\n",
    "    def capitalize_each_Word(self,colname):\n",
    "        \"\"\"Returns a list of tuples. 1st element is the old string and 2nd element\n",
    "        the new string where each word is capitalized.\n",
    "        This list can be used as replacement parameter for replace_values.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        replacements = []\n",
    "        for old in self.data[colname].unique():\n",
    "\n",
    "            if not isinstance(old ,float):\n",
    "                #Capitalize Word if first letter is small else use word\n",
    "                # This way SEO does not turn into Seo \n",
    "                new_list = [x if str.isupper(x[0]) else str.capitalize(x) for x in old.split()]\n",
    "                new = \" \".join(new_list)\n",
    "                if len({old, new}) > 1:\n",
    "                    replacements.append((old,new))\n",
    "\n",
    "        return(replacements)\n",
    "        \n",
    "    def replace_values(self,colname,replacement: list):\n",
    "        \n",
    "        for values in replacement:\n",
    "            if len(set(values))>1:\n",
    "                print(f\"Replace {values[0]} with {values[1]}\")\n",
    "                self.data[colname] = self.data[colname].str.replace(values[0],values[1])\n",
    "        return(self)\n",
    "    \n",
    "    def replace_word(self,colname,replacement: list):\n",
    "        \n",
    "        for values in replacement:\n",
    "            if len(set(values))>1:\n",
    "                print(f\"Replace {values[0]} with {values[1]}\")\n",
    "                self.data[colname] = self.data[\"Role\"].str.replace(fr'\\b{values[0]}\\b', values[1], regex=True)\n",
    "        return(self)\n",
    "            \n",
    "\n",
    "    def make_months_column(self):\n",
    "        self.data[\"Leapsome Deadline Months\"] = pd.to_datetime(self.data[\"Deadline\"],infer_datetime_format=True)\n",
    "        return(self)\n",
    "    \n",
    "    #TODO how to use this function as a property\n",
    "\n",
    "\n",
    "    def get_dico_quarters(self,num,colname):\n",
    "        def dico_quarters(d):\n",
    "        \n",
    "            MonthNr = d.month\n",
    "            year = d.year\n",
    "            \n",
    "            #if not isinstance(MonthNr, float):\n",
    "                #return(\"Unknown\")\n",
    "            if MonthNr >= 1 and MonthNr < 4:\n",
    "                return(f\"{year}-Q1\")\n",
    "            elif MonthNr >= 4 and MonthNr <= 6:\n",
    "                return(f\"{year}-Q2\") \n",
    "            elif MonthNr >= 7 and MonthNr <= 9:\n",
    "                return(f\"{year}-Q3\")\n",
    "            else:\n",
    "                return(f\"{year}-Q4\")\n",
    "\n",
    "        self.data[colname] = self.data[\"Leapsome Deadline Months\"].apply(lambda x: dico_quarters(x) if isinstance(x,pd.Timestamp) else \"unknown\")\n",
    "        return(self)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"PDP_Goals_data_Export_Leapsome_2022-06-10.xlsx\"\n",
    "filepath = f\"../data/raw/{fn}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = TextPreprocessing(pth = filepath)\n",
    "pdp = TP.get_data()\n",
    "pdp = pdp.replace_values('Managed By',[('Laura Wiegmann', 'Steffen Blankenbach')])\n",
    "pdp = pdp.strip_cols([\"Name\",\"Description\"])\n",
    "pdp = pdp.add_missing_year()\n",
    "pdp = pdp.add_missing_delimiter()\n",
    "pdp = pdp.lower_col([\"Name\",\"Description\"])\n",
    "pdp = pdp.extract_url()\n",
    "pdp = pdp.rm_punctuations([\"Name\",\"Description\"])\n",
    "pdp = pdp.split_name_by_pipe()\n",
    "pdp = pdp.combine_text()\n",
    "#pdp.data = pdp.data.rename(columns={\"level\": \"Level\"}, inplace=True)\n",
    "pdp = pdp.make_months_column()\n",
    "pdp = pdp.get_dico_quarters(True,\"Leapsome Deadline Quarter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and merge Goals and Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp = pdp.filter_by_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdp = pdp.preprocess_goals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sentence(sentence):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        sentence (str): A sentence that needs to be categorized.\n",
    "\n",
    "    Returns:\n",
    "        str: A predefinefd category\n",
    "    \"\"\"\n",
    "    str_sentence = str(sentence)\n",
    "\n",
    "    if any(map(str_sentence.__contains__, [\"training\"])):\n",
    "        return \"Training\"\n",
    "    elif any(map(str_sentence.__contains__, [\"completion\", \"done\"])):\n",
    "        return \"Completion\"\n",
    "    elif any(map(str_sentence.__contains__, [\"certifi\", \"zertifi\"])):\n",
    "        return \"Certification\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "pdp.Goals[\"Name_Category\"] = pdp.Goals[\"Name\"].apply(categorize_sentence)\n",
    "pdp.Goals[\"Description_Category\"] = pdp.Goals[\"Description\"].apply(categorize_sentence)\n",
    "\n",
    "pdp.Goals[\"Category\"] = \"\"\n",
    "for count, val in enumerate(pdp.Goals[\"Name_Category\"]):\n",
    "    NC = pdp.Goals.loc[count, \"Name_Category\"]\n",
    "    DC = pdp.Goals.loc[count, \"Description_Category\"]\n",
    "    new_word = None\n",
    "    if NC == \"\" and DC == \"\":\n",
    "        new_word = \"\"\n",
    "    elif NC == DC:\n",
    "        new_word = NC\n",
    "    elif NC != \"\" and DC != \"\":\n",
    "        new_word = f\"{NC} & {DC}\"\n",
    "    else:\n",
    "        new_word = DC if NC == \"\" else NC\n",
    "    pdp.Goals.loc[count, [\"Category\"]] = new_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.Goals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.Goals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.Goals[[\"Name\", \"Name_Category\", \"Description_Category\", \"Category\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unknown_Category = pdp.Goals[pdp.Goals[\"Category\"] == \"\"][\n",
    "    [\"Managed By\", \"Name\", \"Description\", \"Category\"]\n",
    "]\n",
    "Unknown_Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results tbale has many columns with banks because Leapsome does not track these values.\n",
    "- Creation date\n",
    "- Deadline\n",
    "- Weight\n",
    "- Type\n",
    "- Status\n",
    "- Last update\n",
    "- Tag 1\n",
    "- Contributor 1\n",
    "\n",
    "Other columns have same data as in Goals\n",
    "- Owner\n",
    "- Owner ID\n",
    "- Owner Email\n",
    "- Managed By\n",
    "- Managed By ID\n",
    "- Managed By Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results = pdp.Results\n",
    "\n",
    "#Results[\"Description\"] = Results[\"Name\"] \n",
    "\n",
    "\n",
    "Goal_merge =  pdp.Goals.copy(deep= True)\n",
    "Goal_merge.drop(\n",
    "    columns=[\n",
    "        \"level\",\n",
    "        \"Technologie_condense\",\n",
    "        \"Location\"],\n",
    "    inplace=True,\n",
    "    errors='ignore')\n",
    "\n",
    "Result_merge = pdp.Results.copy(deep = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Result_merge.drop(\n",
    "    columns=[\n",
    "        \"Name\",\n",
    "        \"Creation date\",\n",
    "        \"Deadline\",\n",
    "        \"Last Update\",\n",
    "        \"Tag 1\",\n",
    "        \"Contributor 1\",\n",
    "        \"Owner\",\n",
    "        \"Owner ID\",\n",
    "        \"Owner Email\",\n",
    "        \"Managed By\",\n",
    "        \"Managed By ID\",\n",
    "        \"Managed By Email\",\n",
    "        \"Weight\",\n",
    "        \"Type\",\n",
    "        \"Goal / Key Result\",\n",
    "        \"Leaning Platform\",\n",
    "        \"Status\",\n",
    "        \"Goal Year\",\n",
    "        \"Goal Quarter\"\n",
    "    ],\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Goal_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged = pd.merge(\n",
    "    Goal_merge,\n",
    "    Result_merge,\n",
    "    left_on=\"ID\",\n",
    "    right_on=\"Parent ID\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_Goals\", \"_Results\"),\n",
    ")\n",
    "\n",
    "Merged.drop(columns={'ID_Goals'},inplace = True)\n",
    "\n",
    "Merged.rename(columns={'ID_Results':'ID'},inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_columns = Merged.columns.sort_values()\n",
    "first_cols = ['Location',\n",
    "                'Goal Year', \n",
    "                'Goal Quarter',\n",
    "                'Managed By',\n",
    "                'Owner']\n",
    "sorted_columns = sorted_columns.drop(first_cols)\n",
    "\n",
    "new_order = first_cols + list(sorted_columns)\n",
    "new_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged = Merged.reindex(columns=new_order)\n",
    "Merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged[\"Goal Quarter\"] = Merged[\"Goal Quarter\"].str.capitalize() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save goals and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "filepath = Path(\"../data/pyGoals_v2.csv\")\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "pdp.Goals.to_csv(filepath)\n",
    "\n",
    "filepath = Path(\"../data/pyResults_v2.csv\")\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "Results.to_csv(filepath)\n",
    "\n",
    "#filepath = Path(\"pyUnknown_Category.csv\")\n",
    "#filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "#Unknown_Category.to_csv(filepath)\n",
    "\n",
    "filepath = Path(\"../data/pyMerged_v2.csv\")\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "Merged.to_csv(filepath) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"../data/py/pyGoals_v2.xlsx\") as writer:\n",
    "    pdp.Goals.to_excel(writer)  \n",
    "\n",
    "with pd.ExcelWriter(\"../data/py/pyResults_v2.xlsx\") as writer:\n",
    "    pdp.Results.to_excel(writer)  \n",
    "\n",
    "with pd.ExcelWriter(\"../data/py/pyMerged_v2.xlsx\") as writer:\n",
    "    Merged.to_excel(writer)  \n",
    "\n",
    "with pd.ExcelWriter(\"../data/py/pyAppended.xlsx\") as writer:\n",
    "    pdp.data.to_excel(writer)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files need to be copied to /Users/redzesas/Library/CloudStorage/OneDrive-diconiumGmbH/Documents/projekte/power bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"/Users/redzesas/Library/CloudStorage/OneDrive-diconiumGmbH/Documents/projekte/power bi/pdp_report/\"\n",
    "\n",
    "with pd.ExcelWriter(f\"{pth}pyGoals_v2.xlsx\") as writer:\n",
    "    pdp.Goals.to_excel(writer)  \n",
    "\n",
    "with pd.ExcelWriter(f\"{pth}pyResults_v2.xlsx\") as writer:\n",
    "    pdp.Results.to_excel(writer)  \n",
    "\n",
    "with pd.ExcelWriter(f\"{pth}pyAppended.xlsx\") as writer:\n",
    "    pdp.data.to_excel(writer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.data[pdp.data[ 'Goal Quarter']==\"q3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b175db37b8b9a2cf5a7be3e1e0ae7a584e80a60ea5960bcd97892b0f597ea39"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
